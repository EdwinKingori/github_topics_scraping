{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937d8930",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories For GitHub Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490070bf",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "\n",
    "- Browse through the github topic site and select the top topics to scrape.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize the project idea and outline your strategy in a Juptyer notebook.\n",
    "- Tools used include (Python, pandas, BeautifulSoup, requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33376380",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "\n",
    "- The site to scrape https://github.com/topics\n",
    "- Extracting a list of topics from the site. For each topic, I'll extract the topic title, topic page URL and topic description\n",
    "- For each topic, I'll get the top 25 repositories in the topic from the topic page.\n",
    "- For each repository, I'll grab the repo name, username, stars and repo URL\n",
    "- For each topic I'll create a CSV file in the following format:\n",
    "\n",
    "Repo Name,Username,Stars,Repo URL  \n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js  \n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8dbf4",
   "metadata": {},
   "source": [
    "### Scraping a list of topics from Github\n",
    "\n",
    "Steps Taken:\n",
    "\n",
    "- Using requests to download the github page\n",
    "- Utilizing BS4 to parse and extract information \n",
    "- Convert the data extracted to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f7772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fe34b",
   "metadata": {},
   "source": [
    "### Step 1:  Creating a function that uses requests and BeauifulSoup to download the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c44b2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    # download the page\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    # Checking the status of the page (response)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}', format(topic_url))\n",
    "        \n",
    "    #parse using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "554119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topics_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a46329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e841e91",
   "metadata": {},
   "source": [
    "### Step 2: Creating helper functions to parse information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5cab01",
   "metadata": {},
   "source": [
    "#### To get topic titles, we can pick the `p` tags with the `class` \"h1\"\n",
    "\n",
    "![](https://imgur.com/ezVrsA4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd11f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ba586",
   "metadata": {},
   "source": [
    "#### `get_topic_titles` function helps to extract the list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbbbc675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = get_topic_titles(doc)\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb901df",
   "metadata": {},
   "source": [
    "Example of scraped list of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ab7f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a94b4",
   "metadata": {},
   "source": [
    "#### Similar to the above get_topics_function, there are defined functions for extracting descriptions and URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ad349",
   "metadata": {},
   "source": [
    "###### Extracting the topic descriptions: Function code and  instance demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "120128f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e26005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f859c6",
   "metadata": {},
   "source": [
    "Example of scraped descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77da9d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D refers to the use of three-dimensional graphics, modeling, and animation in various industries.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n",
       " 'Amp is a non-blocking concurrency library for PHP.',\n",
       " 'Android is an operating system built by Google designed for mobile devices.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bd9d4",
   "metadata": {},
   "source": [
    "###### Extracting the topic Urls: Function code and  instance demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8963eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-grow-0'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eea6cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1330b",
   "metadata": {},
   "source": [
    "Example of scraped topic urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99a252f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm',\n",
       " 'https://github.com/topics/amphp',\n",
       " 'https://github.com/topics/android']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370d789",
   "metadata": {},
   "source": [
    "#### Combining the above Titles, Descriptions and Urls into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a788ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a41795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ebeae",
   "metadata": {},
   "source": [
    "Let's print the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "579b191e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D refers to the use of three-dimensional grap...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_topics().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea9751c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "titles = get_topic_titles(doc)\n",
    "descriptions = get_topic_descs(doc)\n",
    "urls = get_topic_urls(doc)\n",
    "\n",
    "print(len(titles), len(descriptions), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96872039",
   "metadata": {},
   "source": [
    "### Extracting the top 25 repositories in the topic from the topic page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d639e",
   "metadata": {},
   "source": [
    "#### TO_DO:\n",
    "- Lets now extract a topic from the topics_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7af9d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using Beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d5d29",
   "metadata": {},
   "source": [
    "Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1af500a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page('https://github.com/topics/3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9dfa0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c902ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "titles = get_topic_titles(doc)\n",
    "descriptions = get_topic_descs(doc)\n",
    "urls = get_topic_urls(doc)\n",
    "\n",
    "print(len(titles), len(descriptions), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bf41b",
   "metadata": {},
   "source": [
    "#### TO_DO: \n",
    "- Scrape and return stars earned in the topic extracted\n",
    "- Convert the stars to an integer\n",
    "- Create a function that returns all the required information about a repository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48546f8",
   "metadata": {},
   "source": [
    "Let's first scrape the number of stars for each repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3540827",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags = doc.find_all('span', id='repo-stars-counter-star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea87a805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(star_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "12c21e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97.8k'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f8946",
   "metadata": {},
   "source": [
    "Lets convert the  stars to a defined number, specifically of integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0fca5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1]== 'k': #if the last element is eqal to k\n",
    "        return int(float(stars_str[:-1])*1000) # we remove the last element using stars_str[:-1]\n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39616e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97800\n"
     ]
    }
   ],
   "source": [
    "print(parse_star_count(star_tags[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd2068",
   "metadata": {},
   "source": [
    "Lets now create a function that returns all the required information about a repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc9d4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep_info(h3_tag, star_tag):\n",
    "    #returns all the required information about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    base_url = \"https://github.com\"\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e918bc",
   "metadata": {},
   "source": [
    "Testing function with scraped instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "405a005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "repo_tags = doc.find_all('h3', {'class':h3_selection_class} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c6ca4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"f3 color-fg-muted text-normal lh-condensed\">\n",
       "<a class=\"Link\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"REPOSITORY_CARD\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"REPOSITORY_OWNER_HEADING\",\"actor_id\":null,\"record_id\":97088,\"originating_url\":\"https://github.com/topics/3d\",\"user_id\":null}}' data-hydro-click-hmac=\"c72fbd5c69a8ee7c9c53a4e65de2b93c8fc7552dd793945819639bc165c0f0ba\" data-turbo=\"false\" data-view-component=\"true\" href=\"/mrdoob\">\n",
       "            mrdoob\n",
       "</a>          /\n",
       "          <a class=\"Link text-bold wb-break-word\" data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"REPOSITORY_CARD\",\"click_target\":\"REPOSITORY\",\"click_visual_representation\":\"REPOSITORY_NAME_HEADING\",\"actor_id\":null,\"record_id\":576201,\"originating_url\":\"https://github.com/topics/3d\",\"user_id\":null}}' data-hydro-click-hmac=\"4a2667db3d63a1739c412e059e5da95afe419df83f70949b5d59dc3478f5c79a\" data-turbo=\"false\" data-view-component=\"true\" href=\"/mrdoob/three.js\">\n",
       "            three.js\n",
       "</a> </h3>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rep_info(repo_tags[0], star_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8093b8f",
   "metadata": {},
   "source": [
    "Now lets combine all code written above into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e66fe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_topic_repos(doc):\n",
    "    # Get the h3 tags containing repo title, repo URL and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = doc.find_all('h3', {'class':h3_selection_class} )\n",
    "     # Get star tags\n",
    "    star_tags = doc.find_all('span', id='repo-stars-counter-star')\n",
    "    \n",
    "    topic_repos_dict = {\n",
    "        'username':[],\n",
    "        'repo_name':[],\n",
    "        'stars':[],\n",
    "        'repo_url':[]\n",
    "        }\n",
    "    \n",
    "    # Get repo info\n",
    "    for i in range (len(repo_tags)):\n",
    "        repo_info = get_rep_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "    \n",
    "    return pd.DataFrame(topic_repos_dict)\n",
    "    \n",
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path): # Checking if a file exists so that it can be skipped and not be re-downloaded \n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019faf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a6fa71f",
   "metadata": {},
   "source": [
    "Testing function with the scraped instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd0f1e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>repo_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrdoob</td>\n",
       "      <td>three.js</td>\n",
       "      <td>97800</td>\n",
       "      <td>https://github.com/mrdoob/three.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pmndrs</td>\n",
       "      <td>react-three-fiber</td>\n",
       "      <td>25400</td>\n",
       "      <td>https://github.com/pmndrs/react-three-fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>libgdx</td>\n",
       "      <td>libgdx</td>\n",
       "      <td>22500</td>\n",
       "      <td>https://github.com/libgdx/libgdx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BabylonJS</td>\n",
       "      <td>Babylon.js</td>\n",
       "      <td>22100</td>\n",
       "      <td>https://github.com/BabylonJS/Babylon.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssloy</td>\n",
       "      <td>tinyrenderer</td>\n",
       "      <td>19000</td>\n",
       "      <td>https://github.com/ssloy/tinyrenderer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username          repo_name  stars  \\\n",
       "0     mrdoob           three.js  97800   \n",
       "1     pmndrs  react-three-fiber  25400   \n",
       "2     libgdx             libgdx  22500   \n",
       "3  BabylonJS         Babylon.js  22100   \n",
       "4      ssloy       tinyrenderer  19000   \n",
       "\n",
       "                                      repo_url  \n",
       "0           https://github.com/mrdoob/three.js  \n",
       "1  https://github.com/pmndrs/react-three-fiber  \n",
       "2             https://github.com/libgdx/libgdx  \n",
       "3      https://github.com/BabylonJS/Babylon.js  \n",
       "4        https://github.com/ssloy/tinyrenderer  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_repos(doc).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6817b",
   "metadata": {},
   "source": [
    "### Summary \n",
    "- There is a function that extracts a list of topics\n",
    "- There is a function that create a CSV that stores scraped data from a topics page\n",
    "- Let's create a function that puts them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b701082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    #Creating a folder / directory named 'data' to save the scraped files\n",
    "    os.makedirs('Scraped_data', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows(): # Iterating over rows \n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'Scraped_data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e31573",
   "metadata": {},
   "source": [
    "Let's run it to scrape the top repos for all the topics in the first page of https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7b444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc7d9bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "Scraping top repositories for \"Ajax\"\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping top repositories for \"Atom\"\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "Scraping top repositories for \"C++\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3492d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
