{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937d8930",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories For GitHub Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490070bf",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "\n",
    "- Browse through the github topic site and select the top topics to scrape.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize the project idea and outline your strategy in a Juptyer notebook.\n",
    "- Tools used include (Python, pandas, BeautifulSoup, requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33376380",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "\n",
    "- The site to scrape https://github.com/topics\n",
    "- Extracting a list of topics from the site. For each topic, I'll extract the topic title, topic page URL and topic description\n",
    "- For each topic, I'll get the top 25 repositories in the topic from the topic page.\n",
    "- For each repository, I'll grab the repo name, username, stars and repo URL\n",
    "- For each topic I'll create a CSV file in the following format:\n",
    "\n",
    "Repo Name,Username,Stars,Repo URL  \n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js  \n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8dbf4",
   "metadata": {},
   "source": [
    "### Scraping a list of topics from Github\n",
    "\n",
    "Steps Taken:\n",
    "\n",
    "- Using requests to download the github page\n",
    "- Utilizing BS4 to parse and extract information \n",
    "- Convert the data extracted to a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fe34b",
   "metadata": {},
   "source": [
    "### Step 1:  Creating a function that uses requests and BeauifulSoup to download the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44b2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_topic_page():\n",
    "    # download the page\n",
    "    topic_url = 'https://github.com/topics'\n",
    "    response = requests.get(topic_url)\n",
    "    # Checking the status of the page (response)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}', format(topic_url))\n",
    "        \n",
    "    #parse using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a46329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e841e91",
   "metadata": {},
   "source": [
    "### Step 2: Creating helper functions to parse information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5cab01",
   "metadata": {},
   "source": [
    "#### To get topic titles, we can pick the `p` tags with the `class` \"h1\"\n",
    "\n",
    "![](https://imgur.com/ezVrsA4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ba586",
   "metadata": {},
   "source": [
    "#### `get_topic_titles` function helps to extract the list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbc675",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a94b4",
   "metadata": {},
   "source": [
    "#### Similar to the above get_topics_function, there are defined functions for extracting descriptions and URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ad349",
   "metadata": {},
   "source": [
    "Extracting the topic descriptions: example and  instance demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120128f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "description[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bd9d4",
   "metadata": {},
   "source": [
    "Extracting the topic Urls: example and instance demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8963eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-grow-0'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a252f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370d789",
   "metadata": {},
   "source": [
    "#### Combining the above Titles, Descriptions and Urls functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a788ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    topics_df = pd.DataFrame(topics_dict)\n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96872039",
   "metadata": {},
   "source": [
    "### Extracting the top 25 repositories in the topic from the topic page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edeadf7",
   "metadata": {},
   "source": [
    "#### TO_DO: Extract a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Checking the status of the page (response)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}', format(topic_url))\n",
    "    #parse using beautifulSoup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4dfb8d",
   "metadata": {},
   "source": [
    "Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37556391",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page('https://github.com/topics/3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f062f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.find_all('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b505a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a3adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6259f4a",
   "metadata": {},
   "source": [
    "#### TO_DO: return h3 text from the topic extracted in the doc above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_rep_info(h3_tag, star_tag):\n",
    "    #returns all the required information about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316038c",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d81c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a0394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded49752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h3 tags containing repo title, repo URL and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3', {'class':h3_selection_class} )\n",
    "     # Get star tags\n",
    "    star_tags = topic_doc.find_all('span', id='repo-stars-counter-star')\n",
    "    \n",
    "    topic_repos_dict = {\n",
    "        'username':[],\n",
    "        'repo_name':[],\n",
    "        'stars':[],\n",
    "        'repo_url':[]\n",
    "        }\n",
    "    \n",
    "    # Get repo info\n",
    "    for i in range (len(repo_tags)):\n",
    "        repo_info = get_rep_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "    \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07182e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path): # Checking if a file exists so that it can be skipped and not be re-downloaded \n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e1089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb2039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e825c1c8",
   "metadata": {},
   "source": [
    "### Summary \n",
    "- There is a function that extracts a list of topics\n",
    "- There is a function that create a CSV that stores scraped data from a topics page\n",
    "- Let's create a function that puts them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    #Creating a folder / directory named 'data' to save the scraped files\n",
    "    os.makedirs('Scraped_data', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows(): # Iterating over rows \n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f9c3a",
   "metadata": {},
   "source": [
    "Let's run it to scrape the top repos for all the topics in the first page of https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd84163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
