{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937d8930",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories For GitHub Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490070bf",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "\n",
    "- Browse through the github topic site and select the top topics to scrape.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize the project idea and outline your strategy in a Juptyer notebook.\n",
    "- Tools used include (Python, pandas, BeautifulSoup, requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33376380",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "\n",
    "- The site to scrape https://github.com/topics\n",
    "- Extracting a list of topics from the site. For each topic, I'll extract the topic title, topic page URL and topic description\n",
    "- For each topic, I'll get the top 25 repositories in the topic from the topic page.\n",
    "- For each repository, I'll grab the repo name, username, stars and repo URL\n",
    "- For each topic I'll create a CSV file in the following format:\n",
    "\n",
    "Repo Name,Username,Stars,Repo URL  \n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js  \n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8dbf4",
   "metadata": {},
   "source": [
    "### Scraping a list of topics from Github\n",
    "\n",
    "Steps Taken:\n",
    "\n",
    "- Using requests to download the github page\n",
    "- Utilizing BS4 to parse and extract information \n",
    "- Convert the data extracted to a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fe34b",
   "metadata": {},
   "source": [
    "### Step 1:  Creating a function that uses requests and BeauifulSoup to download the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44b2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_topic_page():\n",
    "    # download the page\n",
    "    topic_url = 'https://github.com/topics'\n",
    "    response = requests.get(topic_url)\n",
    "    # Checking the status of the page (response)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}', format(topic_url))\n",
    "        \n",
    "    #parse using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a46329e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e841e91",
   "metadata": {},
   "source": [
    "### Step 2: Creating helper functions to parse information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5cab01",
   "metadata": {},
   "source": [
    "#### To get topic titles, we can pick the `p` tags with the `class` \"h1\"\n",
    "\n",
    "![](https://imgur.com/ezVrsA4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd11f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ba586",
   "metadata": {},
   "source": [
    "#### `get_topic_titles` function helps to extract the list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbbc675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = get_topic_titles(doc)\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb901df",
   "metadata": {},
   "source": [
    "Example of scraped list of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab7f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a94b4",
   "metadata": {},
   "source": [
    "#### Similar to the above get_topics_function, there are defined functions for extracting descriptions and URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ad349",
   "metadata": {},
   "source": [
    "###### Extracting the topic descriptions: Function code and  instance demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120128f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e26005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f859c6",
   "metadata": {},
   "source": [
    "Example of scraped descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77da9d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D refers to the use of three-dimensional graphics, modeling, and animation in various industries.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n",
       " 'Amp is a non-blocking concurrency library for PHP.',\n",
       " 'Android is an operating system built by Google designed for mobile devices.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bd9d4",
   "metadata": {},
   "source": [
    "###### Extracting the topic Urls: Function code and  instance demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8963eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-grow-0'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea6cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1330b",
   "metadata": {},
   "source": [
    "Example of scraped topic urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a252f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm',\n",
       " 'https://github.com/topics/amphp',\n",
       " 'https://github.com/topics/android']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370d789",
   "metadata": {},
   "source": [
    "#### Combining the above Titles, Descriptions and Urls into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a788ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a41795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ebeae",
   "metadata": {},
   "source": [
    "Let's print the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579b191e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D refers to the use of three-dimensional grap...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_topics().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9751c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96872039",
   "metadata": {},
   "source": [
    "### Extracting the top 25 repositories in the topic from the topic page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d639e",
   "metadata": {},
   "source": [
    "#### TO_DO:\n",
    "- Lets now extract a topic from the topics_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7af9d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Checking the status of the page (response)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}', format(topic_url))\n",
    "    #parse using beautifulSoup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d5d29",
   "metadata": {},
   "source": [
    "Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1af500a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page('https://github.com/topics/3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c902ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea591bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291bf41b",
   "metadata": {},
   "source": [
    "#### TO_DO: \n",
    "- Scrape and return stars earned in the topic extracted\n",
    "- Convert the stars to an integer\n",
    "- Scrape and return h3 text from the topic extracted in the doc above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48546f8",
   "metadata": {},
   "source": [
    "Let's first scrape the number of stars for each repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3540827",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags = doc.find_all('span', id='repo-stars-counter-star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea87a805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(star_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12c21e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97.7k'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_tags[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f8946",
   "metadata": {},
   "source": [
    "Lets convert the  stars to a defined number, specifically of integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0fca5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1]== 'k': #if the last element is eqal to k\n",
    "        return int(float(stars_str[:-1])*1000) # we remove the last element using stars_str[:-1]\n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39616e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97700\n"
     ]
    }
   ],
   "source": [
    "print(parse_star_count(star_tags[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_rep_info(h3_tag, star_tag):\n",
    "    #returns all the required information about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e918bc",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a30f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a005f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h3 tags containing repo title, repo URL and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3', {'class':h3_selection_class} )\n",
    "     # Get star tags\n",
    "    star_tags = topic_doc.find_all('span', id='repo-stars-counter-star')\n",
    "    \n",
    "    topic_repos_dict = {\n",
    "        'username':[],\n",
    "        'repo_name':[],\n",
    "        'stars':[],\n",
    "        'repo_url':[]\n",
    "        }\n",
    "    \n",
    "    # Get repo info\n",
    "    for i in range (len(repo_tags)):\n",
    "        repo_info = get_rep_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "    \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4e0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca378222",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path): # Checking if a file exists so that it can be skipped and not be re-downloaded \n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ad008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f196c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe6817b",
   "metadata": {},
   "source": [
    "### Summary \n",
    "- There is a function that extracts a list of topics\n",
    "- There is a function that create a CSV that stores scraped data from a topics page\n",
    "- Let's create a function that puts them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    #Creating a folder / directory named 'data' to save the scraped files\n",
    "    os.makedirs('Scraped_data', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows(): # Iterating over rows \n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e31573",
   "metadata": {},
   "source": [
    "Let's run it to scrape the top repos for all the topics in the first page of https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7b444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
